import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.autograd import Variable
from torch.utils.data import DataLoader, Dataset

import matplotlib.pyplot as plt
from PIL import Image
import numpy as np

import cv2
from google.colab.patches import cv2_imshow


mean_gray = 0.1307
stddev_gray = 0.3081


transforms_original = transforms.Compose([transforms.ToTensor(), transforms.Normalize((mean_gray,), (stddev_gray))])

transforms_photo = transforms.Compose([transforms.Resize((28, 28)),  transforms.ToTensor(), transforms.Normalize((mean_gray,), (stddev_gray))])


train_dataset = datasets.MNIST(root = "./data", train = True, transform = transforms_original, download = True)

test_dataset = datasets.MNIST(root = "./data", train = False, transform = transforms_original)


random_image = train_dataset[20][0].numpy() * stddev_gray + mean_gray
plt.imshow(random_image.reshape(28, 28), cmap = "gray")


print(train_dataset[20][1])


batch_size = 100

train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)

test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)


# len(train_dataset / batch_size = len(train_loader
# 60000 / 100 = 600
print("Training Set Images: {}".format(len(train_dataset)))
print("Test Set Images. {}".format(len(test_dataset)))
print("Training Set Batches: {}".format(len(train_loader)))
print("Test Set Batches: {}".format(len(test_loader)))


class CNN(nn.Module):

  def __init__(self):

    super(CNN, self).__init__()

    self.cnn1 = nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size = 3, stride = 1, padding = 1)
    self.batchnorm1 = nn.BatchNorm2d(8)
    self.relu = nn.ReLU()
    self.maxpool1 = nn.MaxPool2d(kernel_size = 2)

    self.cnn2 = nn.Conv2d(in_channels = 8, out_channels = 32, kernel_size = 5, stride = 1, padding = 2)
    self.batchnorm2 = nn.BatchNorm2d(32)
    self.maxpool2 = nn.MaxPool2d(kernel_size = 2)

    # MaxPool dan sonra her feature map 7 (14/2)
    # feature map e flatten uygula
    # 32 feature map var (7x7)
    # 32 * 7 * 7

    self.fc1 = nn.Linear(in_features = 1568, out_features = 600)
    self.dropout = nn.Dropout(p = 0.5)
    self.fc2 = nn.Linear(in_features = 600, out_features = 10)

  def forward(self, x):
    x = self.cnn1(x)
    x = self.batchnorm1(x)
    x = self.relu(x)
    x = self.maxpool1(x)
    x = self.cnn2(x)
    x = self.batchnorm2(x)
    x = self.maxpool2(x)
    x = x.view(-1, 1568)
    x = self.fc1(x)
    x = self.relu(x)
    x = self.dropout(x)
    x = self.fc2(x)
    return x


model = CNN()
CUDA = torch.cuda.is_available()

if CUDA:
  model = model.cuda()

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)


iteration = 0
correct = 0

for i, (inputs, labels) in enumerate(train_loader):

  CUDA = torch.cuda.is_available()

  if CUDA:
    inputs = inputs.cuda()
    labels = labels.cuda()

  print("Her bir iterasyonda ...")
  print("Inputs Shape:", inputs.shape)
  print("Labels Shape:", labels.shape)
  output = model(inputs)
  print("Output Shape:", output.shape)
  _, predicted = torch.max(output, 1)
  print("Predicted Shape:", predicted.shape)
  print("Predicted Tensor:")
  print(predicted)
  correct += (predicted == labels).sum()
  break


num_epochs = 25

train_loss = []
test_loss = []
train_accuracy = []
test_accuracy = []

for epoch in range(num_epochs):

  correct = 0
  iterations = 0
  iter_loss = 0

  model.train()

  for i, (inputs, labels) in enumerate(train_loader):
    CUDA = torch.cuda.is_available()

    if CUDA:
      inputs = inputs.cuda()
      labels = labels.cuda()

    outputs = model(inputs)
    loss = loss_fn(outputs, labels)
    iter_loss += loss.item()
    optimizer.zero_grad()
    loss.backward()
    optimizer.step() #update the weights

    _, predicted = torch.max(outputs, 1)
    correct += (predicted == labels).sum()
    iterations += 1

  train_loss.append(iter_loss/iterations)
  train_accuracy.append(100*correct/len(train_dataset))

  testing_loss = 0.0
  correct = 0
  iterations = 0

  model.eval() #NN evaluation mode a sok

  for i, (inputs, labels) in enumerate(test_loader):
    CUDA = torch.cuda.is_available()

    if CUDA:
      inputs = inputs.cuda()
      labels = labels.cuda()

    outputs = model(inputs)
    loss = loss_fn(outputs, labels)
    testing_loss += loss.item()

    _, predicted = torch.max(outputs, 1)
    correct += (predicted == labels).sum()
    iterations += 1

  test_loss.append(testing_loss/iterations)
  test_accuracy.append(100*correct/len(test_dataset))

  print("Epoch {}/{}, Training Loss: {:.3f}, Training Accuracy: {:.3f}, Testing Loss: {:.3f}, Testing Accuracy: {:.3f}".format(
epoch+1, num_epochs, train_loss[-1], train_accuracy[-1], test_loss[-1], test_accuracy[-1]))


fig = plt.figure(figsize = (10, 10))
plt.plot(train_loss, label = "Training Loss")
plt.plot(test_loss, label = "Test Loss")
plt.legend()
plt.show()


def predict(img_name, model):
  image = cv2.imread(img_name,0)
  ret, thresholded = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)
  img = 255-thresholded
  cv2_imshow(img)
  cv2.waitKey(0)
  cv2.destroyAllWindows()
  img = Image.fromarray(img)
  img = transforms_photo(img)
  img = img.view(1, 1, 28, 28)
  img = Variable(img)

  model.eval()

  if torch.cuda.is_available():
    model = model.cuda()
    img = img.cuda()

  output = model(img)
  print(output)
  print(output.data)
  _, predicted = torch.max(outputs, 1)

  return predicted.item()


# prediction = predict("ut.png", model)
# print("Tahmin Edilen Label: {}". format(prediction))


plt.imshow(test_dataset[20][0].reshape(28, 28), cmap = "gray")
img = test_dataset[20][0].resize_((1, 1, 28, 28))
label = test_dataset[20][1]

model.eval()

CUDA = torch.cuda.is_available()

if CUDA:
  model = model.cuda()
  img = img.cuda()

output = model(img)
_, predicted = torch.max(output, 1)

print("Tahmin Edilen Label: {}". format(predicted.item()))
print("Ger√ßek Label: {}".format(label))
